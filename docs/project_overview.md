# Project Overview

## Purpose
This project demonstrates beginner‑to‑intermediate SQL analysis skills using the Titanic passenger dataset.  
The goal is to practice real‑world SQL workflows in a structured, professional format while building a reproducible database environment and performing meaningful analysis.

Unlike the Python Data Cleaning project, this project begins with a **pre‑cleaned dataset**, allowing the focus to remain entirely on SQL fundamentals and analytical techniques.

---

## Tools & Languages Used

### **Languages**
- SQL (SQLite dialect)
- Python (for ETL and database loading)

### **Tools / Technologies**
- **SQLite** — lightweight relational database engine  
- **DB Browser for SQLite** — database exploration and query execution  
- **Azure Data Studio** — optional SQL environment  
- **Python 3.x** — used to load CSV data into SQLite  
- **Git & GitHub** — version control and project hosting  
- **VS Code** — primary development environment  

These tools reflect a realistic analytics workflow and demonstrate your ability to work across SQL, Python, and database tooling.

---

## Objectives
This project was designed to help develop and reinforce the following skills:

- Working with relational databases (SQLite)
- Loading data using SQL and Python ETL
- Writing clean, structured SQL queries
- Performing exploratory data analysis (EDA) in SQL
- Using aggregations and grouping to uncover patterns
- Applying multi‑condition filtering for targeted insights
- Using window functions for ranking and distribution analysis
- Using Common Table Expressions (CTEs) to simplify complex logic
- Documenting SQL workflows in a clear, professional manner

---

## What This Project Covers
This SQL project includes:

### **Database Setup**
- Creating a SQLite database
- Defining a table schema
- Loading a cleaned CSV into the database using Python and SQL

### **Exploratory SQL Analysis**
- Family structure analysis
- Survival rate calculations
- Fare and demographic exploration
- Null and data quality checks

### **Intermediate SQL Concepts**
- Window functions (`RANK`, `PERCENT_RANK`)
- CTEs for modular, readable analysis
- Derived columns (e.g., family size, age buckets)

### **Documentation**
- High‑level README for portfolio consistency
- Detailed breakdowns inside `/docs`

---

## What This Project Does *Not* Cover
To keep the project focused and beginner‑friendly, the following topics are intentionally excluded:

- Data cleaning (handled in a separate Python project)
- Machine learning or predictive modeling
- Advanced SQL joins across multiple tables
- Visualization dashboards (optional future enhancement)

---

## Why the Titanic Dataset?
The Titanic dataset is widely used for analytics practice because it contains:

- Numeric, categorical, and demographic fields  
- Clear relationships between variables  
- Real‑world patterns (class, gender, age, fare, family size)  
- Enough complexity to practice SQL meaningfully  
- Enough simplicity to avoid overwhelming beginners  

It’s an ideal dataset for building SQL confidence while producing insights that are easy to interpret.

---

## Summary
This project provides a structured, hands‑on environment for practicing SQL in a way that mirrors real analytics workflows.  
It demonstrates your ability to:

- Build and manage a database  
- Write clean, modular SQL  
- Apply intermediate analytical techniques  
- Extract meaningful insights from structured data  
- Document your work professionally  

For a full breakdown of the SQL queries and logic, see `sql_analysis_breakdown.md`.
